{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Opening the Black Box with LRP: A Hands-on Guide to Explainable AI for LLMs\n",
    "\n",
    "by Reduan Achtibat & Anton Segeler\n"
   ],
   "id": "6dc8c719e9d4cb48"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup",
   "id": "cbe765cba1c350fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# installing packages with pip\n",
    "%pip install -r requirements.txt"
   ],
   "id": "f428d43393bb9457",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.models.llama import modeling_llama\n",
    "from lxt.efficient import monkey_patch\n",
    "from lxt.utils import clean_tokens\n",
    "import gradio as gr\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from jscatter import Scatter\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "import umap\n",
    "import functools\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.lines import Line2D"
   ],
   "id": "75b70087a722b8a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else (\"mps\" if torch.mps.is_available() else \"cpu\"))\n",
    "print(device)\n",
    "\n",
    "# Load the model\n",
    "path = 'unsloth/Llama-3.2-1B-Instruct'\n",
    "\n",
    "model = modeling_llama.LlamaForCausalLM.from_pretrained(\n",
    "    path,\n",
    "    device_map=device,\n",
    "    dtype=torch.bfloat16,\n",
    "    attn_implementation=\"eager\",\n",
    ")\n",
    "print(model)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "print(tokenizer)"
   ],
   "id": "37cacae3afbb3937"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
